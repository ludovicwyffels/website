---
title: "Gestion des environnements Angular en livraison continue"
authors: [ludovicwyffels]
date: 2019-09-08T18:15:11+02:00
summary: "Mise en oeuvre de la configuration de l'environnement dynamique dans Angular pour √©viter un build par environnement"
draft: false
categories: ["Node.js", "DevOps", "Angular"]
tags:
  - "Node.js"
  - "Angular"
  - "TypeScript"
  - "DevOps"
---

Dans les applications m√©tiers, nous rencontrons souvent une configuration de livraison continue comportant plusieurs stages. Chaque √©tape a sa configuration pour acc√©der aux syst√®mes p√©riph√©riques sp√©cifiques √† l'environnement. Pour ce faire, nous devons g√©rer les configurations bas√©es sur les stages.

Angular CLI est livr√© avec certains concepts int√©gr√©s permettant de g√©rer diff√©rents environnements.

Mais quelle est leur fiabilit√© dans un environnement de livraison continu ? ü§î

## Livraison continue - une courte introduction

La livraison continue r√©sulte du mouvement agile. La r√©troaction it√©rative est √† la base. Il est essentiel d'apprendre des exp√©riences pratiques et d'int√©grer ces commentaires.

La livraison continue prend des id√©es agiles et d√©finit une approche pour livrer des logiciels test√©s automatiquement dans des cycles courts.

> La diffusion continue consiste √† cr√©er un pipeline pour automatiser le processus de publication du logiciel

## √âtapes de livraison continue

Un sch√©ma typique dans la livraison continue est le _steging_. Dans une configuration de livraison continue typique, nous avons diff√©rents stages avec des objectifs diff√©rents.
Chaque validation entra√Æne une ex√©cution du pipeline sur notre serveur CI. Les ex√©cutions r√©ussies sur la branche `master` entra√Ænent un d√©ploiement sur l'un de nos stages.

![Continuous Deployment](./images/continuous-deployment.png)

Dans l'exemple ci-dessus, la phase de `test` contient une snapshot de la branche `master`. √Ä certains intervalles, par exemple, apr√®s chaque sprint, nous pouvons d√©ployer au stade interm√©diaire (`staging`). C'est √† ce stade que les tests de r√©ception finaux sont effectu√©s. Une fois accept√©, l'artefact est d√©plac√© en production.

Bien s√ªr, certaines entreprises ont un temps de production plus rapide. Certains d√©ploient m√™me chaque commit directement en production.

Mais dans la plupart des applications li√©es aux entreprises, il est bon d‚Äôavoir une √©tape avant la production. Cela permet √† nos _product owners_, repr√©sentants commerciaux et testeurs d'avoir un dernier aper√ßu et de v√©rifier la logique m√©tier.

## Build une fois - d√©ployer partout

Il est essentiel de ne construire votre artefact qu'une seule fois et de le d√©placer d'une √©tape √† l'autre.
Cette approche garantit que le m√™me artefact qui a √©t√© test√© entre √©galement en production.

## Les environnements Angular et livraison continue, sont-il adapt√© ? ü§î

Angular CLI est livr√©e avec un m√©canisme int√©gr√© de fichier d'environnement. Voyons comment ils fonctionnent.

Lors de la g√©n√©ration d'un tout nouveau projet, il existe un `environment.ts`et un `envrironment.prod.ts`. De plus, nous pouvons toujours ajouter √† ces fichiers de nouveaux fichiers d'environnement dans le dossier `environment ` et les configurer dans votre fichier `angular.json`.

Pendant le build, l'environnement souhait√© est ensuite transmis en tant qu'argument √† la commande de build. Le CLI utilise ensuite le fichier d'environnement correct et remplace le fichier par d√©faut pendant le build, que nous pouvons ensuite importer avec la ligne suivante

```ts
import {environment} from '../environments/environment';
```

Maintenant que nous connaissons le concept int√©gr√© de la CLI angulaire. Voyons en quoi cela correspond aux principes de la livraison continue.

Il est donc essentiel de noter que Angular CLI d√©finit l‚Äôenvironnement pendant la construction. Cela signifie que nous devons cr√©er notre application avant chaque d√©ploiement sur une √©tape sp√©cifique.


Cette approche comporte quelques risques.

Si vous cr√©ez votre application √† chaque fois avant de d√©ployer, il se peut que l'artefact que vous avez test√© ne soit pas le m√™me que celui qui entre en production.

> Il est important de r√©aliser qu‚Äôun processus de build n‚Äôest pas toujours d√©terministe. M√™me si le m√™me code entre dans la construction, il n‚Äôest pas garanti que le m√™me artefact sortira.

L‚Äôartefact ne d√©pend pas seulement de votre code, il d√©pend √©galement des biblioth√®ques tierces, des mises √† jour du syst√®me d‚Äôexploitation ou d‚Äôautres modifications de l‚Äôenvironnement qui se produisent avec le temps.

Rappelez-vous √† l'√©poque o√π nous avions un `package.lock.json`. √Ä l'√©poque, les builds √©taient encore moins pr√©dictives. Les biblioth√®ques tierces apparaissent souvent avec un `^` dans notre `package.json`. Malgr√© `semver`, les nouvelles versions d'une biblioth√®que tierce produisaient parfois une incompatibilit√© avec une autre d√©pendance qui entra√Ænait la rupture de votre application.

> Plus vous pouvez maintenir la coh√©rence entre les d√©ploiements, plus le d√©ploiement en production est susceptible de se d√©rouler sans heurts.

**La livraison continue et les fichiers d'environnement fournis par Angular CLI ne conviennent pas!**

**Dans la livraison continue, votre artefact doit obtenir des configurations sp√©cifiques √† l'environnement au d√©marrage ou √† l'ex√©cution. Angular CLI, en revanche, obtient ces configurations au moment du build.**

Alors, comment combiner les id√©es de la livraison continue avec notre application angulaire?

Il existe diff√©rentes approches pour combiner les id√©es de livraison continue avec Angular CLI. Chacun comporte des avantages et des inconv√©nients.

Regardons-les.



## Configurer l'h√¥te comme assets - Monter les fichiers de configuration par environnement

Au lieu d'extraire la configuration sur un endpoint REST, nous extrayons directement un fichier JSON avec des configurations situ√©es dans notre dossier `assets`.

Nous allons donc cr√©er un dossier de `config` √† l‚Äôint√©rieur `assets` et y placer un `JSON` contenant les configurations sp√©cifiques √† l‚Äôenvironnement local.

Mais comment charge-t-on le fichier `configuration.json`? Au travers d'un service au travers duquel nous r√©cup√©rons le fichier √† partir du dossier `assets`.

```ts
import {Injectable} from '@angular/core';
import {HttpClient} from '@angular/common/http';
import {Observable} from 'rxjs';
import {shareReplay} from 'rxjs/operators';

interface Configuration {
  resourceServerA: string;
  resourceServerB: string;
  stage: string;
}

@Injectable({providedIn: 'root'})
export class ConfigAssetLoaderService {

  private readonly CONFIG_URL = 'assets/config/config.json';
  private configuration$: Observable<Configuration>;

  constructor(private http: HttpClient) {
  }

  public loadConfigurations(): any {
    if (!this.configuration$) {
      this.configuration$ = this.http.get<Configuration>(this.CONFIG_URL).pipe(
        shareReplay(1)
      );
    }
    return this.configuration$;
  }
```

`ConfigurationAssetsLoaderService` charge maintenant notre fichier `assets/config/config.json` qui contient toutes les configurations. Mais comment pouvons-nous changer ces configurations par rapport √† l'environnement actuel dans lequel nous nous trouvons?

Nous allons simplement h√©berger notre configuration sur chaque √©tape, puis monter le fichier `configuration.json` dans le dossier `assets`. Lorsque votre pod d√©marre, nous montons votre configuration dans le r√©pertoire `assets/config`.

Il est important de noter que vous cr√©ez un dossier `config` √† l'int√©rieur du dossier `assets`. Nous ne pouvons pas utiliser une hi√©rarchie √† plat. Lors du montage, tous les fichiers du dossier mont√© sont supprim√©s.

La mani√®re concr√®te de monter des volumes d√©pend de votre outil de CI. Sur mon projet, nous utilisons Kubernetes pour nos d√©ploiements. Kubernetes nous fournit des `ConfigMaps` qui peuvent √™tre une propri√©t√© ou m√™me un fichier de configuration complet. Donc, sur Kubernetes, nous avons diff√©rents stages. Chaque stage h√©berge ensuite des configurations sp√©cifiques et les monte dans notre dossier `assets/config` au d√©marrage du pod.

```yaml
volumeMounts:
  - mountPath: /usr/share/nginx/html/assets/config
    name: yourVolumeName
```

Nous avons maintenant vu deux approches dont la mise en oeuvre c√¥t√© client est tr√®s similaire. Nous avons cr√©√© un service qui r√©cup√®re les configurations √† partir d'un endpoint REST ou du dossier `assets`.

Nous avons donc vu deux mani√®res d'utiliser un service pour acc√©der √† des configurations. Mais quand appelons-nous ces services?

Eh bien, r√©ponse courte, c‚Äôest √† vous de voir. Il y a des moments diff√©rents o√π il est logique de les appeler. Chacun vient avec des avantages et des inconv√©nients.



## Remplacer les configurations par environnement

Dans cet exemple, nous utilisons les fichiers d'environnement Angular tels quels. Un `environment.ts`et un `environment.prod.ts`.

M√™me si nous avons plus de stages que la production et le d√©veloppement, nous distinguons seulement ces deux-l√†. Pour le d√©veloppement local, nous utilisons le fichier `environment.ts`. Tous les autres stages sont g√©r√©s par `environment.prod.ts`.

Mais comment ?

Notre `environment.prod.ts` ne contient pas les valeurs r√©elles; il contient des valeurs d'espace r√©serv√© qui seront √©cras√©es √† chaque √©tape par un script de construction.

Un exemple de fichier `environment.prod.ts` pourrait ressembler √† ceci:

```ts
export const environment = {
  resourceServerA: 'REPLACED_BY_BUILD_RESOURCEA',
  resourceServerB: 'REPLACED_BY_BUILD_RESOURCEB',
  stage: 'REPLACED_BY_BUILD_STAGE',
};
```

Lorsque nous d√©marrons notre serveur Web, nous pouvons ensuite utiliser un script `start.sh` qui remplacera les espaces r√©serv√©s.

```bash
#!/bin/sh

# replace static values with environment-variables
if [ -n "$RESOURCEA" ]; then
  sed -i "s#REPLACED_BY_BUILD_RESOURCEA#$AUTHSERVER_URL#g" /usr/share/nginx/html/main.*.bundle.js
fi

# start webserver
exec nginx
```

Nous ex√©cutons ensuite ce script au d√©marrage. Par exemple, dans notre fichier Docker.

```Dockerfile
# Dockerfile
...
# Start nginx via script, which replaces static urls with environment variables
ADD start.sh /usr/share/nginx/start.sh
RUN chmod +x /usr/share/nginx/start.sh
CMD /usr/share/nginx/start.sh
```

Cette approche, du moins pour moi, est un peu "hacky". Remplacer des cha√Ænes dans un paquet n‚Äôest probablement pas le moyen le plus agr√©able. Il comporte en outre le risque de remplacer quelque chose qui ne devrait pas √™tre remplac√©.

Si vous d√©cidez quand m√™me d'utiliser cette approche, il est extr√™mement important d'avoir de bons espaces r√©serv√©s. Utilisez des caract√®res sp√©ciaux que vous n'utilisez g√©n√©ralement pas dans les noms de variables.

## Conclusion

Angular est livr√© avec des fichiers d‚Äôenvironnement qui nous permettent de g√©rer des configurations sp√©cifiques √† l‚Äôenvironnement. Ils ne r√©pondent pas aux exigences d'une configuration de livraison continue.

Les fichiers d'environnement Angular sont utilis√©s pendant la phase de build. En mode de livraison continue, il est essentiel de d√©ployer le m√™me artefact √† diff√©rents stages. Par cons√©quent, nous devons transmettre les configurations d'environnement au d√©marrage ou √† l'ex√©cution.

En fonction de votre configuration, nous pouvons charger des configurations via un service. Soit directement √† partir d'un backend ou de notre dossier d'actifs.

Il est donc recommand√© de les mettre en cache.



---



Un des gros d√©fauts de la fa√ßon dont Angular CLI traite les environnements, dans la culture DevOps c'est mieux de **build une seule fois et de d√©ployer sur plusieurs environnements**, hors Angular CLI veut que vous cr√©er un buildnpm s√©par√© par environnement.

Pourquoi devriez-vous build une seule fois et r√©utiliser cette version dans tous les environnements?

La raison pour laquelle vous ne souhaitez pas cr√©er une version distincte pour chaque environnement est la suivante:

1. Cela ralentit les pipelines d'int√©gration continue (CI), car il doit cr√©er un build pour chaque environnement.
1. Cela augmente le risque d'erreurs / de diff√©rences dans diff√©rents environnements, car les versions sont s√©par√©es
1. Il ajoute des informations inutiles sur d'autres environnements dans le code
1. Pour des raisons de s√©curit√©, vous pourriez ne pas vouloir afficher d'informations confidentielles dans la configuration de l'environnement, qui est enregistr√©e dans Git.

Tous ces probl√®mes me font me demander pourquoi **Angular CLI opte pour une version par environnement**. Je voulais bien s√ªr une solution √† ces probl√®mes.

Comment ces probl√®mes sont-ils r√©solus ?

En faisant en sorte que le serveur de d√©ploiement **substitue un fichier config.json, charg√© au moment de l'ex√©cution** par l'application.

## Faire en sorte qu'une application Angular utilise des configurations dynamiques

Nous voulons que l'application Angular ne comporte que deux fichiers d'environnement: `environment.ts` et `environment.prod.ts`.

Pourquoi deux environnements, vous pouvez demander? Un pour les d√©veloppeurs locaux, o√π vous pouvez mettre ce que vous voulez pour servir localement et un autre pour cr√©er l‚Äôapplication. Ces fichiers d'environnement tirent l'essentiel de ses valeurs d'un fichier `app-config.json` charg√© lors de l'ex√©cution, contrairement √† la codification en dur de toutes les informations sur l'environnement dans les fichiers d'environnement.

## Cr√©er une nouvelle application Angular

La premi√®re √©tape consiste √† cr√©er une nouvelle application Angular en ouvrant le terminal, acc√©der au r√©pertoire souhait√© pour l'application et taper:

```bash
ng new dynamic-config-demo
```

Et cela devrait cr√©er une nouvelle application Angular pour vous.

## Chargement du fichier config.json au d√©marrage

Toute la configuration de l'environnement va √™tre stock√©e dans un fichier `app-config.json` utilis√© par le fichier `environment.ts` pour r√©f√©rencer ces valeurs en toute s√©curit√©.

Nous cr√©ons simplement un fichier JSON vide dans le dossier `assets` appel√© `app-config.json`.

L'√©tape suivante consiste √† **charger le fichier config.json** √† l'aide d'un service d'initialisation `app.init.ts`:

```ts
import { Injectable } from '@angular/core';
import { from } from 'rxjs';
import { filter, map, switchMap, tap } from 'rxjs/operators';
declare var window: any;

@Injectable()
export class AppInitService {

  // This is the method you want to call at bootstrap
  // Important: It should return a Promise
  public init() {
    return from(
        fetch('assets/app-config.json').then(function(response) {
          return response.json();
        })
      ).pipe(
        map((config) => {
        window.config = config;
        return;
      })).toPromise();
  }
}
```

Ce service s'ex√©cutera au d√©marrage et garantira que la configuration de l'application est r√©cup√©r√©e en utilisant `fetch` pour obtenir le fichier de configuration, puis enregistrez-le dans `window` pour le rendre globalement disponible pour l'application. Notez que lorsque vous utilisez `fetch`, vous aurez peut-√™tre besoin de polyfills pour la prise en charge du navigateur IE.

Le service d'initialisation d'application est configur√© dans le module `app.module` comme suit:

```ts
export function init_app(appLoadService: AppInitService) {
  return () => appLoadService.init();
}
@NgModule({
  declarations: [AppComponent, ComponentAComponent, ComponentBComponent],
  imports: [BrowserModule, CoreModule, HttpClientModule],
  providers: [
    AppInitService,
    {
      provide: APP_INITIALIZER,
      useFactory: init_app,
      deps: [AppInitService],
      multi: true
    }
  ],
  bootstrap: [AppComponent]
})
export class AppModule {}
```

L‚Äôutilisation d‚Äôun service d‚Äôinitialisation d‚Äôapplication cr√©e un l√©ger retard sur le temps de d√©marrage de l‚Äôapplication, mais des √©l√©ments simples comme celui-ci n‚Äôauront pas d‚Äôimpact consid√©rable sur le temps de d√©marrage. N√©anmoins, je vous recommande d‚Äôindiquer √† vos utilisateurs d‚Äôattendre avec une spinner de chargement.

## Faire en sorte que les fichiers d'environnement utilisent des valeurs dynamiques

Maintenant que nous chargeons le JSON de configuration de mani√®re dynamique et que nous les enregistrons dans `window`, nous voulons pouvoir les r√©f√©rencer en toute s√©curit√©. Pour ce faire, nous devrions avoir trois fichiers d‚Äôenvironnement: `environment`, `environment.prod` et `dynamic-environment`.

`environment` est destin√© √† √™tre utilis√© localement, `environment.prod` est destin√© √† la production et `dynamic-environment` est partag√© avec `environment` et `environment.prod` afin de fournir une configuration dynamique.

`dynamic-environment` ressemble √† ceci:

```ts
declare var window: any;

export class DynamicEnvironment {
  public get environment() {
    return window.config.environment;
  }
}
```

Ceci est utilis√© dans `environnement` comme celui-ci:

```ts
import { DynamicEnvironment } from './dynamic-environment';
class Environment extends DynamicEnvironment {

  public production: boolean;
  constructor() {
    super();
    this.production = false;
  }
}

export const environment = new Environment();
```

Vous pouvez trouver une d√©monstration compl√®te d'une application angulaire √† configuration dynamique sur mon Github ici.

## Substitution du fichier config.json sur le serveur de d√©ploiement

Maintenant que nous avons configur√© l'application pour la configuration dynamique, la prochaine √©tape consiste √† configurer le remplacement du fichier de configuration sur le serveur de d√©ploiement.

Vous pouvez faire cela en utilisant **Octopus**, qui a une fonction intelligente pour **remplacer un fichier JSON** par des valeurs de configuration pour l'environnement. Les autres serveurs de d√©ploiement devraient avoir des fonctionnalit√©s similaires pour substituer un fichier JSON juste avant de d√©ployer l'application sur le serveur frontal.

## Conclusion

Nous avons discut√© des probl√®mes pos√©s par la m√©thode de ‚ÄúAngular CLI‚Äù pour g√©rer la configuration de l‚Äôenvironnement avec **un build par environnement**. Nous avons √©galement cherch√© √† d√©terminer l‚Äôint√©r√™t de **build une version √† la fois**. Nous avons examin√© comment impl√©menter cela √† l'aide d'un service app.init qui chargeait un fichier de configuration dynamique lors de l'initialisation, avec des valeurs d√©finies par le serveur de d√©ploiement.
